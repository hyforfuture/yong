{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习作业 6 - 支持向量机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在本作业练习中，我们将使用支持向量机（SVM）来构建垃圾邮件分类器。本次作业内容包括：\n",
    "\n",
    "（1）从一些简单的2D数据集开始使用SVM来查看它们的工作原理。 观察不同的C值对分类结果的影响，了解高斯核函数用于非线性分类的用法。\n",
    "\n",
    "（2）对一组原始电子邮件进行一些预处理工作，并使用SVM在处理的电子邮件上构建分类器，以确定它们是否为垃圾邮件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 观察不同的C值对分类效果的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from scipy.io import loadmat\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）将数据用散点图表示，其中类标签由符号表示（+表示正类，o表示负类）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data = loadmat('data/hw6data1.mat')\n",
    "\n",
    "data = pd.DataFrame(raw_data['X'], columns=['X1', 'X2'])\n",
    "data['y'] = raw_data['y']\n",
    "\n",
    "positive = data[data['y'].isin([1])]\n",
    "negative = data[data['y'].isin([0])]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.scatter(positive['X1'], positive['X2'], s=50, marker='x', label='Positive')\n",
    "ax.scatter(negative['X1'], negative['X2'], s=50, marker='o', label='Negative')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotDecisionBoundary(clf,data):  # 绘制超平面函数\n",
    "    x_min, x_max=np.array(data['X1']).min(), np.array(data['X1']).max()\n",
    "    y_min, y_max=np.array(data['X2']).min(), np.array(data['X2']).max()\n",
    "    xx, yy=np.meshgrid(np.linspace(x_min,x_max,500),np.linspace(y_min,y_max,500))\n",
    "    Z=clf.predict(np.c_[xx.ravel(),yy.ravel()])\n",
    "    Z=Z.reshape(xx.shape)\n",
    "    plt.contour(xx,yy,Z,colors = 'red') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）调用scikit-learn中的svm.LinearSVC库来执行SVM。初始的C值为1。关于scikit-learn的帮助，请自行查阅资料学习（http://sklearn.apachecn.org/#/docs/68）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.LinearSVC(C=1, loss='hinge', max_iter=50000) # 初始化一个分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）尝试不同的C值，观察对结果的影响。先看一下C=1的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs1=svc.fit(data[['X1', 'X2']], data['y']) # 训练分类器\n",
    "svc.score(data[['X1', 'X2']], data['y']) # 计算准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其次，让我们看看如果C的值越大，会发生什么，例如C=500。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc2 = svm.LinearSVC(C=500, loss='hinge', max_iter=1000000)\n",
    "clfs2=svc2.fit(data[['X1', 'X2']], data['y'])\n",
    "svc2.score(data[['X1', 'X2']], data['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "通过增大C的值，可以得到准确率接近1的完美分类结果，但是决策边界并不理想。 通过两种方法可以看出来这种不理想的情况：\n",
    "\n",
    "a. 查看每个类别预测的<font color=red>置信水平</font>，即样本点与超平面距离的函数。\n",
    "\n",
    "b. 绘制决策边界（超平面）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SVM 1 Confidence'] = svc.decision_function(data[['X1', 'X2']])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.scatter(data['X1'], data['X2'], s=50, c=data['SVM 1 Confidence'], cmap='seismic')\n",
    "plotDecisionBoundary(clfs1,data) \n",
    "ax.set_title('SVM (C=1) Decision Confidence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SVM 2 Confidence'] = svc2.decision_function(data[['X1', 'X2']])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.scatter(data['X1'], data['X2'], s=50, c=data['SVM 2 Confidence'], cmap='seismic')\n",
    "plotDecisionBoundary(clfs2,data) \n",
    "ax.set_title('SVM (C=100) Decision Confidence')\n",
    "plt.show()\n",
    "\n",
    "# 请回答生成的散点图，颜色深浅的含义\n",
    "# 红色和蓝色的深浅分辨代表的含义是："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 高斯核函数\n",
    "\n",
    "（1）现在我们将从线性SVM转移到能够使用核函数进行非线性分类的SVM。 \n",
    "我们不使用scikit-learn中内置的高斯核函数，请自行实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 实现高斯核函数\n",
    "def gaussian_kernel(x1, x2, sigma):\n",
    "    return #请在这里补充一行代码来完成高斯核函数的实现\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([1.0, 1.0, 2.0])\n",
    "x2 = np.array([0.0, 4.0, -1.0])\n",
    "sigma = 2\n",
    "\n",
    "gaussian_kernel(x1, x2, sigma)\n",
    "\n",
    "#此处的结果将在作业的客观题中作答\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）接下来，我们换另一个数据集，这次用非线性决策边界。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = loadmat('data/hw6data2.mat')\n",
    "\n",
    "data = pd.DataFrame(raw_data['X'], columns=['X1', 'X2'])\n",
    "data['y'] = raw_data['y']\n",
    "\n",
    "positive = data[data['y'].isin([1])]\n",
    "negative = data[data['y'].isin([0])]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.scatter(positive['X1'], positive['X2'], s=30, marker='x', label='Positive')\n",
    "ax.scatter(negative['X1'], negative['X2'], s=30, marker='o', label='Negative')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）对于该数据集，我们将使用内置的高斯核函数RBF构建支持向量机分类器，并检查其对训练数据的准确性。 \n",
    "\n",
    "为了可视化决策边界，这一次我们将根据负样本的预测概率来对点做红色阴影。\n",
    "\n",
    "同时，我们还可以绘制决策边界来进行观察，请自行添加代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc3 = svm.SVC(C=100, gamma=10, kernel='rbf', probability=True)\n",
    "# 查阅svm.SVC相关资料，回答此处的gamma参数和rbf核函数的关系\n",
    "# gamma代表：\n",
    "clfs3=svc3.fit(data[['X1', 'X2']], data['y'])\n",
    "svc3.score(data[['X1', 'X2']], data['y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Probability'] = svc3.predict_proba(data[['X1', 'X2']])[:,0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "# 此处补充一行代码绘制决策边界\n",
    "\n",
    "ax.scatter(data['X1'], data['X2'], s=30, c=data['Probability'], cmap='Reds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 寻找最优参数\n",
    "接下来，我们使用第三个数据集，该数据集包括训练和验证集，并且基于验证集性能为SVM模型找到最优超参数。\n",
    "尽管我们可以使用scikit-learn的内置网格搜索来做到这一点，但是为了帮助大家更好的理解网格搜索原理，我们将从头开始实现一个简单的网格搜索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = loadmat('data/hw6data3.mat')\n",
    "\n",
    "X = raw_data['X']\n",
    "Xval = raw_data['Xval']\n",
    "y = raw_data['y'].ravel()\n",
    "yval = raw_data['yval'].ravel()\n",
    "\n",
    "C_values = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]\n",
    "gamma_values = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]\n",
    "\n",
    "best_score = 0\n",
    "best_params = {'C': None, 'gamma': None}\n",
    "\n",
    "for C in C_values:\n",
    "    for gamma in gamma_values:\n",
    "        #此处补充完善3行代码，完成网格搜索\n",
    "        svc = 请补充\n",
    "        svc.fit(请补充)\n",
    "        score = 请补充\n",
    "        #补充结束\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params['C'] = C\n",
    "            best_params['gamma'] = gamma\n",
    "\n",
    "best_score, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建垃圾邮件过滤器\n",
    "现在，我们开始使用SVM来构建垃圾邮件过滤器。 \n",
    "在本部分的样本数据中，包括spamTrina.mat和spamTest.mat，分别对应的是训练集和测试集。\n",
    "我们已经对垃圾邮件数据进行了预处理：例如，去除邮件中的HTML标记，只保留纯文本信息，将邮件中的字词映射到字典中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_train = loadmat('data/spamTrain.mat')\n",
    "spam_test = loadmat('data/spamTest.mat')\n",
    "\n",
    "# 观察 spam_train 训练集中的数据\n",
    "spam_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spam_train['X']\n",
    "Xtest = spam_test['Xtest']\n",
    "y = spam_train['y'].ravel()\n",
    "ytest = spam_test['ytest'].ravel()\n",
    "\n",
    "# 观察X, y, Xtest, ytest 形状\n",
    "X.shape, y.shape, Xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们能看到每个邮件已经转换为一个向量，其中1,899个维对应于词汇表中的1,899个单词。 它们的值为二进制，表示邮件中是否存在单词。 我们用测试集数据来评估一下训练的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里使用svm.SVC的默认参数来进行训练，请回答C和gamma的默认值是多少\n",
    "svc = svm.SVC(gamma='auto')\n",
    "svc.fit(X, y)\n",
    "print('Training accuracy = {0}%'.format(np.round(svc.score(X, y) * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy = {0}%'.format(np.round(svc.score(Xtest, ytest) * 100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的结果是使用默认参数的，测试集精度已经达到了95.3%，<font color=red>请尝试参数调整来获得更高的精度（如96%以上）</font>。\n",
    "\n",
    "本次作业到这里就结束了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
